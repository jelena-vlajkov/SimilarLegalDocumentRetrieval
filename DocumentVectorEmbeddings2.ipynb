{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d37e439",
   "metadata": {},
   "source": [
    "<h1> Document Vector Embeddings </h1>\n",
    "\n",
    "Initial experiment will be perfomed based on the experiment by Sugathadasa et al. [https://arxiv.org/pdf/1805.10685.pdf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9fe08e",
   "metadata": {},
   "source": [
    "<h2> Text Preprocessing </h2>\n",
    "\n",
    "First step is to create a <i> document corpus </i> which is a subset of most important sentences in each document. We can do that by implementing the <i> PageRank </i> algorithm. Before we do that, we need to preprocess the document by cleaning the text of unwanted charachters and common words. We used lemmatization and case-folding to lowercase as first steps in cleaning the documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834644a4",
   "metadata": {},
   "source": [
    "<h5> Required libraries </h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b5f1e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38d43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "import nltk.data\n",
    "import pandas as pd\n",
    "from text_rank import analyze \n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances\n",
    "import en_core_web_sm\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de293030",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_DOCUMENTS = 1395\n",
    "NUM_OF_SENTENCES = 50\n",
    "NUM_OF_CHARACTERS = 10\n",
    "\n",
    "URL = \"https://www.courtlistener.com/api/rest/v3/opinions/\"\n",
    "\n",
    "RUN_TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e66ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document(file_name):\n",
    "    data = \"\"\n",
    "    with open(file_name) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data[\"plain_text\"].replace(\"\\n\", \" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddc5516",
   "metadata": {},
   "source": [
    "<h2> <i> TextRank </i> algorithm </h2>\n",
    "\n",
    "<i> TextRank </i> algorithm will be implemented based on the work of Mihalcea et al [https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf]. <br>\n",
    "We use this algorithm for extracting \"most valuable\" sentences in a document.  <br> <br>\n",
    "<i> TextRank </i> algorithm is implemented in a python script named <i> text_rank.py </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9de2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_textrank(text):\n",
    "    sorted_sentences = analyze(text, NUM_OF_SENTENCES)\n",
    "    return sorted_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01429612",
   "metadata": {},
   "source": [
    "Sentences that are shorter than N characters should be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59da7b",
   "metadata": {},
   "source": [
    "<h2> Text processing after <i> TextRank </i> algorithm </h2>\n",
    "\n",
    "After the <i> TextRank </i> algorithm we apply lemmatization to each word in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33adbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemma Tokenizer called by TfIdfVectorizer\n",
    "\n",
    "class LemmaTokenizer():\n",
    "    def __init__(self):\n",
    "        self.spacynlp = spacy.load('en_core_web_sm')\n",
    "    def __call__(self, doc):\n",
    "        nlpdoc = self.spacynlp(doc)\n",
    "        nlpdoc = [token.lemma_.lower() for token in nlpdoc if (not token.is_punct)]\n",
    "        return nlpdoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87b75121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_list2str(s): \n",
    "    str1 = \"\" \n",
    "    for ele in s: \n",
    "        str1 += \" \" + ele  \n",
    "    return str1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c6c8a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatized_txt2str(s):\n",
    "    str1 = \"\" \n",
    "    for ele in s: \n",
    "        for ele2 in ele:\n",
    "            if ele2.isspace():\n",
    "                continue\n",
    "            str1 += \" \" + ele2  \n",
    "    return str1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c35681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_tokenizer = LemmaTokenizer()\n",
    "def lemmatize(sentences):\n",
    "    # Because of the TextRank algorithm, we have to split the document into sentences to create the document corpus \n",
    "    # (document corpus is the k most important sentences after applying TextRank algorithm)\n",
    "\n",
    "\n",
    "    sentences = tokenizer.tokenize(sorted_list2str(sentences))\n",
    "    sentences = [x for x in sentences if len(x) > NUM_OF_CHARACTERS]\n",
    "    lemmatized_text = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        one_sentence = lemma_tokenizer(sentence)\n",
    "        lemmatized_text.append(one_sentence)\n",
    "    lemmatized_text = lemmatized_txt2str(lemmatized_text)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3da9d0",
   "metadata": {},
   "source": [
    "<h2> Apply TF-IDF </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d424e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_vectorizer(df):\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
    "    tfidf_vector = tfidf_vectorizer.fit_transform(df.iloc[:, 1].tolist())\n",
    "    tfidf_df = pd.DataFrame(tfidf_vector.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "        \n",
    "    return tfidf_vectorizer, tfidf_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e675299",
   "metadata": {},
   "source": [
    "<h2> Global Term Frequency </h2>\n",
    "\n",
    "To see how important a word is in the whole dataset, we calculate GTF_IDF matrix applying the formula below:\n",
    "\n",
    "GTF_IDF = TF_IDF * sum(TF_IDF) / NUM_OF_DOCUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a72e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_gtfidf(tf_df):\n",
    "    sum_of_idfs = tfidf_df.sum(axis = 0)\n",
    "    for i in range(len(tfidf_df.columns)):\n",
    "        tf_df[tfidf_df.columns[i]] = tf_df[tfidf_df.columns[i]].apply(lambda x: x * (sum_of_idfs[i] / NUM_OF_DOCUMENTS))\n",
    "        \n",
    "    return tf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f14e84",
   "metadata": {},
   "source": [
    "<h2> The Experiment </h2>\n",
    "\n",
    "We run the whole pipeline on N documents from the CourtListener database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a37f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = [\"id\", \"document\"])\n",
    "if RUN_TRAIN:\n",
    "    i = 0\n",
    "    for file_name in [file for file in os.listdir(\"data/train/\") if file.endswith('.json')]:\n",
    "        try:\n",
    "            print(i)\n",
    "            document = get_document(\"data/train/\" + file_name)\n",
    "            sorted_sentences = apply_textrank(document)\n",
    "            df.loc[i] = lemmatize(sorted_sentences)\n",
    "            df.loc[i] = [file_name, lemmatize(sorted_sentences)]\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            i += 1\n",
    "            continue\n",
    "else:\n",
    "    df = pd.read_csv(\"train_textrank.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd2695e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>174995.json</td>\n",
       "      <td>09 1504 united states of america appellee v. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>174996.json</td>\n",
       "      <td>in this case the district court instruct the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>175074.json</td>\n",
       "      <td>the bia affirm the april 3 2008 opinion of an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>175075.json</td>\n",
       "      <td>moreover fia 's affidavit explicitly confirm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>175076.json</td>\n",
       "      <td>objection your honor to the line of questioni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>1391</td>\n",
       "      <td>198335.json</td>\n",
       "      <td>then on august 15 1994 toyota advise citi tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>1392</td>\n",
       "      <td>198336.json</td>\n",
       "      <td>the court then say briefly that while petrone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>1393</td>\n",
       "      <td>198337.json</td>\n",
       "      <td>upon careful review of the record appellant '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>1394</td>\n",
       "      <td>198338.json</td>\n",
       "      <td>of medical examiners 375 u.s. 411 1964 we non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1395</td>\n",
       "      <td>198339.json</td>\n",
       "      <td>in this case the defendant be convict of aid ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1396 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0           id  \\\n",
       "0              0  174995.json   \n",
       "1              1  174996.json   \n",
       "2              2  175074.json   \n",
       "3              3  175075.json   \n",
       "4              4  175076.json   \n",
       "...          ...          ...   \n",
       "1391        1391  198335.json   \n",
       "1392        1392  198336.json   \n",
       "1393        1393  198337.json   \n",
       "1394        1394  198338.json   \n",
       "1395        1395  198339.json   \n",
       "\n",
       "                                               document  \n",
       "0      09 1504 united states of america appellee v. ...  \n",
       "1      in this case the district court instruct the ...  \n",
       "2      the bia affirm the april 3 2008 opinion of an...  \n",
       "3      moreover fia 's affidavit explicitly confirm ...  \n",
       "4      objection your honor to the line of questioni...  \n",
       "...                                                 ...  \n",
       "1391   then on august 15 1994 toyota advise citi tha...  \n",
       "1392   the court then say briefly that while petrone...  \n",
       "1393   upon careful review of the record appellant '...  \n",
       "1394   of medical examiners 375 u.s. 411 1964 we non...  \n",
       "1395   in this case the defendant be convict of aid ...  \n",
       "\n",
       "[1396 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17790d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test = pd.DataFrame(columns = [\"id\", \"document\"])\n",
    "if RUN_TRAIN:\n",
    "    i = 0\n",
    "    for file_name in [file for file in os.listdir(\"data/test/\") if file.endswith('.json')]:\n",
    "        try:\n",
    "            document = get_document(\"data/test/\" + file_name)\n",
    "            sorted_sentences = apply_textrank(document)\n",
    "            df_test.loc[i] = lemmatize(sorted_sentences)\n",
    "            df_test.loc[i] = [file_name, lemmatize(sorted_sentences)]\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "else:\n",
    "    df_test = pd.read_csv(\"test_textrank.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc9f482f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>198340.json</td>\n",
       "      <td>finally the government argue even if turner '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>198341.json</td>\n",
       "      <td>5861(d 5871 2 be a felon in know possession o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>198342.json</td>\n",
       "      <td>receive evidence interrogate examine and cros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>198343.json</td>\n",
       "      <td>yet the high maximum set by the guideline be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>198631.json</td>\n",
       "      <td>98 1710 united states appellee v. michael b. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>414</td>\n",
       "      <td>199125.json</td>\n",
       "      <td>see downes 182 u.s. at 380 harlan j. dissent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>415</td>\n",
       "      <td>199126.json</td>\n",
       "      <td>credibility determination be for the jury not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>416</td>\n",
       "      <td>199127.json</td>\n",
       "      <td>see e.g. manso pizarro v. secretary of health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>417</td>\n",
       "      <td>199129.json</td>\n",
       "      <td>the jury find for volkswagen and we reason th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>418</td>\n",
       "      <td>199130.json</td>\n",
       "      <td>1998 cert 1998 cert john ward llambias by app...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0           id  \\\n",
       "0             0  198340.json   \n",
       "1             1  198341.json   \n",
       "2             2  198342.json   \n",
       "3             3  198343.json   \n",
       "4             4  198631.json   \n",
       "..          ...          ...   \n",
       "414         414  199125.json   \n",
       "415         415  199126.json   \n",
       "416         416  199127.json   \n",
       "417         417  199129.json   \n",
       "418         418  199130.json   \n",
       "\n",
       "                                              document  \n",
       "0     finally the government argue even if turner '...  \n",
       "1     5861(d 5871 2 be a felon in know possession o...  \n",
       "2     receive evidence interrogate examine and cros...  \n",
       "3     yet the high maximum set by the guideline be ...  \n",
       "4     98 1710 united states appellee v. michael b. ...  \n",
       "..                                                 ...  \n",
       "414   see downes 182 u.s. at 380 harlan j. dissent ...  \n",
       "415   credibility determination be for the jury not...  \n",
       "416   see e.g. manso pizarro v. secretary of health...  \n",
       "417   the jury find for volkswagen and we reason th...  \n",
       "418   1998 cert 1998 cert john ward llambias by app...  \n",
       "\n",
       "[419 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6935a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"train_textrank.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63aa6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"test_textrank.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4db0a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer, tfidf_df = call_vectorizer(df)\n",
    "train_gtf_idf = calculate_gtfidf(tfidf_df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d93f24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174995     0.000704\n",
       "174996     0.000704\n",
       "175074     0.000704\n",
       "175075     0.000704\n",
       "175076     0.000704\n",
       "            ...    \n",
       "198336     0.000704\n",
       "198337     0.000704\n",
       "198338     0.000704\n",
       "198339     0.000704\n",
       "json      24.091859\n",
       "Length: 1397, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gtf_idf.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb400f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cos_similarity(): \n",
    "    results = pd.DataFrame(columns = [\"verdict\", \"indexes\"])\n",
    "    for i, doc in enumerate(df_test.iloc[:, 1]): \n",
    "        tfidf_test = vectorizer.transform([doc])\n",
    "        tfidf_test = pd.DataFrame(tfidf_test.toarray(), columns=vectorizer.get_feature_names())\n",
    "        tfidf_test = calculate_gtfidf(tfidf_test)\n",
    "        distances = cosine_similarity(tfidf_test, train_gtf_idf).flatten()\n",
    "        indexes = np.argsort(distances)[::-1]\n",
    "        indexes = indexes[:100]\n",
    "        results = results.append({ \n",
    "            \"verdict\" : df_test.iloc[i, 0], \n",
    "            \"indexes\" : indexes}, ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad9a0e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19040/118777634.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcos_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19040/1643540331.py\u001b[0m in \u001b[0;36mcos_similarity\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtfidf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtfidf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtfidf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_gtfidf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_gtf_idf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19040/3421140600.py\u001b[0m in \u001b[0;36mcalculate_gtfidf\u001b[1;34m(tf_df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_gtfidf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msum_of_idfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtf_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtfidf_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtfidf_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum_of_idfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mNUM_OF_DOCUMENTS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  10706\u001b[0m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10707\u001b[0m         ):\n\u001b[1;32m> 10708\u001b[1;33m             return NDFrame.sum(\n\u001b[0m\u001b[0;32m  10709\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10710\u001b[0m             )\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  10444\u001b[0m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10445\u001b[0m     ):\n\u001b[1;32m> 10446\u001b[1;33m         return self._min_count_stat_function(\n\u001b[0m\u001b[0;32m  10447\u001b[0m             \u001b[1;34m\"sum\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10448\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_min_count_stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  10426\u001b[0m                 \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10427\u001b[0m             )\n\u001b[1;32m> 10428\u001b[1;33m         return self._reduce(\n\u001b[0m\u001b[0;32m  10429\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10430\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   9849\u001b[0m             \u001b[1;31m# After possibly _get_data and transposing, we are now in the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9850\u001b[0m             \u001b[1;31m#  simple case where we can use BlockManager.reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9851\u001b[1;33m             \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_failures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   9852\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9853\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreduce\u001b[1;34m(self, func, ignore_failures)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         \u001b[0mres_blocks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1283\u001b[1;33m             \u001b[0mnbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1284\u001b[0m             \u001b[0mres_blocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mreduce\u001b[1;34m(self, func, ignore_failures)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mblk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m   9821\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9822\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9823\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   9824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9825\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnansum\u001b[1;34m(values, axis, skipna, min_count, mask)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_null_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mthe_sum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_maybe_null_out\u001b[1;34m(result, axis, mask, shape, min_count)\u001b[0m\n\u001b[0;32m   1438\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1440\u001b[1;33m             \u001b[0mnull_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1441\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1442\u001b[0m             \u001b[1;31m# we have no nulls, kept mask=None in _maybe_get_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     46\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     47\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = cos_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79a3f1e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19040/962467392.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d74bf76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"results/text_rank.csv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa3736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd76763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
