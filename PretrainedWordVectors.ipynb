{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a305d68b",
   "metadata": {},
   "source": [
    "<h1> Document Vectorization </h1>\n",
    "\n",
    "This experiment will be based on Google News pretrained Word2Vec and GloVe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86368ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances\n",
    "import spacy\n",
    "import en_core_web_md\n",
    "import string \n",
    "import gensim.downloader\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_DOCUMENTS = 5\n",
    "URL = \"https://www.courtlistener.com/api/rest/v3/opinions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590bdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document(endpoint):\n",
    "    r = requests.get(url = endpoint)\n",
    "    data = r.json()\n",
    "    verdict_text = data[\"plain_text\"]\n",
    "    verdict_text = verdict_text.replace(\"\\n\", \" \")\n",
    "    \n",
    "    return verdict_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc22a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e77325bc",
   "metadata": {},
   "source": [
    "<h2> Google News Word2Vec </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d9115b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad9414",
   "metadata": {},
   "source": [
    "<h2> GloVe </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85bb7c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====---------------------------------------------] 11.0% 41.2/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================--------------------------------] 36.1% 135.6/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================------------------------------] 40.4% 151.9/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================--------------------------] 48.5% 182.3/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================------------------------] 52.8% 198.5/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================-------------------] 62.1% 233.7/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================--------------] 73.4% 275.9/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================================--------] 85.0% 319.6/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================================--] 96.6% 363.3/376.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glove = gensim.downloader.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38fa20f",
   "metadata": {},
   "source": [
    "<h3> Function for fitting training sets for average and sum of vectors </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e38c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_training(model):\n",
    "    df_sum = pd.DataFrame()\n",
    "    df_avg = pd.DataFrame()\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        document = row['document']\n",
    "        words = document.split()\n",
    "        word_vec = np.zeros((300, ))\n",
    "        for word in words:\n",
    "            if word.lower() in model.vocab:\n",
    "                word_vec += model[word.lower()]\n",
    "            elif word in model.vocab:\n",
    "                word_vec += model[word]\n",
    "    \n",
    "        word_vec_avg = word_vec / len(words)\n",
    "        word_vec = pd.Series(word_vec)\n",
    "        df_sum = df_sum.append(pd.Series(word_vec), ignore_index=True)\n",
    "        df_avg = df_avg.append(pd.Series(word_vec_avg), ignore_index=True)\n",
    "    return df_sum, df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdd1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx(type, n, document, model, avg):\n",
    "    df_q = pd.DataFrame()\n",
    "    words = document.split()\n",
    "    word_vec = np.zeros((300, ))\n",
    "    \n",
    "    for word in words:\n",
    "        if word.lower() in model.vocab:\n",
    "            word_vec += model[word.lower()]\n",
    "        elif word in model.vocab:\n",
    "            word_vec += model[word]\n",
    "            \n",
    "    if avg == True:\n",
    "        word_vec = word_vec/len(words)\n",
    "        \n",
    "    df_q = df_q.append(pd.Series(word_vec), ignore_index=True)\n",
    "\n",
    "    strtype, asc, dftrain = getOtherVars(type, avg, model)\n",
    "\n",
    "    distances = type(df_q, dftrain).flatten()\n",
    "    indexes = np.argsort(distances)[::asc]\n",
    "    indexes = indexes[:n]\n",
    "    \n",
    "    return indexes, strtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569324bb",
   "metadata": {},
   "source": [
    "<h3>  Inverse document frequency - IDF </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84fb80c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15612/1397695777.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0midf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "idf = {}\n",
    "for i in range(len(df.iloc[:, 0])):\n",
    "    tokens = df.iloc[i, 0].translate(str.maketrans('', '', string.punctuation)).lstrip().rstrip().split()\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            idf[w.lower()].add(i)\n",
    "        except:\n",
    "            idf[w.lower()] = {i}\n",
    "\n",
    "for key, value in idf.items():\n",
    "    idf[key] = math.log(len(df.iloc[:, 0]) / (len(value)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea00c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_idf(type, n, document, model, avg):\n",
    "    df_q = pd.DataFrame()\n",
    "    \n",
    "    words = document.split()\n",
    "    word_vec = np.zeros((300, ))\n",
    "    for word in words:\n",
    "        idfCoeff = 1\n",
    "        if word.lower() in idf:\n",
    "            idfCoeff = idf[word.lower()]\n",
    "        if word.lower() in model.vocab:\n",
    "            word_vec += model[word.lower()]*idfCoeff\n",
    "        elif word in model.vocab:\n",
    "            word_vec += model[word]*idfCoeff\n",
    "            \n",
    "    if avg == True:\n",
    "        word_vec = word_vec / len(words)\n",
    "        \n",
    "    df_q = df_q.append(pd.Series(word_vec), ignore_index=True)\n",
    "\n",
    "    strtype, asc, dftrain = getOtherVars(type, avg, model)\n",
    "\n",
    "    distances = type(df_q, dftrain).flatten()\n",
    "    indexes = np.argsort(distances)[::asc]\n",
    "    indexes = indexes[:n]\n",
    "    \n",
    "    return indexes, strtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d2e59",
   "metadata": {},
   "source": [
    "<h3>  Part-of-speech - POS </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c253d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = {}\n",
    "\n",
    "for sentence in df.iloc[:, 0]:\n",
    "    for token in nlp(sentence.lower()):\n",
    "        pos[token.text] = {token.pos_ : None}\n",
    "        \n",
    "for sentence in df_test.iloc[:, 1]:\n",
    "    for token in nlp(sentence.lower()):\n",
    "        pos[token.text] = {token.pos_ : None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b0ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, posTagAndVal in pos.items():\n",
    "    \n",
    "    for tag in posTagAndVal:\n",
    "        if tag == \"NOUN\":\n",
    "            posTagAndVal[tag] = 0.7\n",
    "        elif tag == \"PROPN\": \n",
    "            posTagAndVal[tag] = 0.9\n",
    "        elif tag == \"ADJ\":\n",
    "            posTagAndVal[tag] = 0.8\n",
    "        elif tag == \"ADV\":\n",
    "            posTagAndVal[tag] = 0.7\n",
    "        elif tag == \"VERB\":\n",
    "            posTagAndVal[tag] = 0.6\n",
    "        else:\n",
    "            posTagAndVal[tag] = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c593a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_pos(type, n, document, model, avg):\n",
    "    df_q = pd.DataFrame()\n",
    "    \n",
    "    words = document.split()\n",
    "    word_vec = np.zeros((300, ))\n",
    "    for word in words:\n",
    "        posCoeff = 1\n",
    "        if word.lower() in pos:\n",
    "            posCoeff = next(iter(pos[word.lower()].values()))\n",
    "        if word.lower() in model.vocab:\n",
    "            word_vec += model[word.lower()]*posCoeff\n",
    "        elif word in model.vocab:\n",
    "            word_vec += model[word]*posCoeff\n",
    "            \n",
    "    if avg == True:\n",
    "        word_vec = word_vec / len(words)\n",
    "        \n",
    "    df_q = df_q.append(pd.Series(word_vec), ignore_index=True)\n",
    "\n",
    "    strtype, asc, dftrain = getOtherVars(type, avg, model)\n",
    "\n",
    "    distances = type(df_q, dftrain).flatten()\n",
    "    indexes = np.argsort(distances)[::asc]\n",
    "    indexes = indexes[:n]\n",
    "    \n",
    "    return indexes, strtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02692d",
   "metadata": {},
   "source": [
    "<h3>   Named Entity Recognition - NER </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = {}\n",
    "\n",
    "for sentence in df.iloc[:, 0]:\n",
    "    for token in nlp(sentence.lower()).ents:\n",
    "        ner[token.text] = {token.label_: None}\n",
    "        \n",
    "for sentence in df_test.iloc[:, 1]:\n",
    "    for token in nlp(sentence.lower()).ents:\n",
    "        ner[token.text] = {token.label_: None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a9a7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, nerTagAndVal in ner.items():\n",
    "    \n",
    "    for tag in nerTagAndVal:\n",
    "        if (tag == \"LOCATION\") or (tag == \"ORG\") or (tag == \"NORP\") or (tag == \"MONEY\") or (tag == \"WORK_OF_ART\") or (tag == \"LAW\"):\n",
    "            nerTagAndVal[tag] = 1.75\n",
    "        elif (tag == \"GPE\") or (tag == \"DATE\") or (tag == \"PERSON\") or (tag == \"FAC\"): \n",
    "            nerTagAndVal[tag] = 1.5\n",
    "        elif (tag == \"ORDINAL\") or (tag == \"CARDINAL\") or (tag == \"PRODUCT\") or (tag == \"PERCENT\") or (tag == \"TIME\"):\n",
    "            nerTagAndVal[tag] = 1.2\n",
    "        else:\n",
    "            nerTagAndVal[tag] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c7d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_ner(type, n, document, model, avg):\n",
    "    df_q = pd.DataFrame()\n",
    "    words = document.split()\n",
    "    word_vec = np.zeros((300, ))\n",
    "    for word in words:\n",
    "        nerCoeff = 1\n",
    "        if word.lower() in ner:\n",
    "            nerCoeff = next(iter(ner[word.lower()].values()))\n",
    "        if word.lower() in model.vocab:\n",
    "            word_vec += model[word.lower()]*nerCoeff\n",
    "        elif word in model.vocab:\n",
    "            word_vec += model[word]*nerCoeff\n",
    "            \n",
    "    if avg == True:\n",
    "        word_vec = word_vec / len(words)\n",
    "        \n",
    "    df_q = df_q.append(pd.Series(word_vec), ignore_index=True)\n",
    "\n",
    "    strtype, asc, dftrain = getOtherVars(type, avg, model)\n",
    "\n",
    "    distances = type(df_q, dftrain).flatten()\n",
    "    indexes = np.argsort(distances)[::asc]\n",
    "    indexes = indexes[:n]\n",
    "    \n",
    "    return indexes, strtype "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c694ddf",
   "metadata": {},
   "source": [
    "<h3> The Experiment </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordEmbs = [word2vec, glove]\n",
    "functions = [get_idx, get_idx_idf, get_idx_pos, get_idx_ner]\n",
    "avgs = [True, False]\n",
    "measures = [cosine_similarity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2420e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
